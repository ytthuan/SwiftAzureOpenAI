// Generated Swift Models from OpenAPI Specification
// DO NOT EDIT: This file is automatically generated

import Foundation

/// Generated enum for AzureAIFoundryModelsApiVersion
public enum GeneratedAIFoundryModelsApiVersion: String, Codable, CaseIterable {
    case v1 = "v1"
    case preview = "preview"
}

/// Generated enum for AzureFileExpiryAnchor
public enum GeneratedFileExpiryAnchor: String, Codable, CaseIterable {
    case created_at = "created_at"
}

/// Generated enum for OpenAI.ImageDetail
public enum GeneratedImageDetail: String, Codable, CaseIterable {
    case low = "low"
    case high = "high"
    case auto = "auto"
}

/// Generated enum for OpenAI.ResponseErrorCode
public enum GeneratedResponseErrorCode: String, Codable, CaseIterable {
    case server_error = "server_error"
    case rate_limit_exceeded = "rate_limit_exceeded"
    case invalid_prompt = "invalid_prompt"
    case vector_store_timeout = "vector_store_timeout"
    case invalid_image = "invalid_image"
    case invalid_image_format = "invalid_image_format"
    case invalid_base64_image = "invalid_base64_image"
    case invalid_image_url = "invalid_image_url"
    case image_too_large = "image_too_large"
    case image_too_small = "image_too_small"
    case image_parse_error = "image_parse_error"
    case image_content_policy_violation = "image_content_policy_violation"
    case invalid_image_mode = "invalid_image_mode"
    case image_file_too_large = "image_file_too_large"
    case unsupported_image_media_type = "unsupported_image_media_type"
    case empty_image_file = "empty_image_file"
    case failed_to_download_image = "failed_to_download_image"
    case image_file_not_found = "image_file_not_found"
}

/// Generated model for AzureContentFilterBlocklistResult
public struct GeneratedContentFilterBlocklistResult: Codable, Equatable {
    /// The pairs of individual blocklist IDs and whether they resulted in a filtering action.
    public let details: [SAOAIJSONValue]?

    /// A value indicating whether any of the detailed blocklists resulted in a filtering action.
    public let filtered: Bool

}

/// Generated model for AzureContentFilterCompletionTextSpan
public struct GeneratedContentFilterCompletionTextSpan: Codable, Equatable {
    /// Offset of the first UTF32 code point which is excluded from the span. This field is always equal to completion_start_offset for empty spans. This field is always larger than completion_start_offset...
    public let completionEndOffset: Int

    /// Offset of the UTF32 code point which begins the span.
    public let completionStartOffset: Int

    private enum CodingKeys: String, CodingKey {
        case completionEndOffset = "completion_end_offset"
        case completionStartOffset = "completion_start_offset"
    }

}

/// Generated model for AzureContentFilterCompletionTextSpanDetectionResult
public struct GeneratedContentFilterCompletionTextSpanDetectionResult: Codable, Equatable {
    /// Detailed information about the detected completion text spans.
    public let details: [GeneratedContentFilterCompletionTextSpan]

    /// Whether the labeled content category was detected in the content.
    public let detected: Bool

    /// Whether the content detection resulted in a content filtering action.
    public let filtered: Bool

}

/// Generated model for AzureContentFilterCustomTopicResult
public struct GeneratedContentFilterCustomTopicResult: Codable, Equatable {
    /// The pairs of individual topic IDs and whether they are detected.
    public let details: [SAOAIJSONValue]?

    /// A value indicating whether any of the detailed topics resulted in a filtering action.
    public let filtered: Bool

}

/// Generated model for AzureContentFilterDetectionResult
public struct GeneratedContentFilterDetectionResult: Codable, Equatable {
    /// Whether the labeled content category was detected in the content.
    public let detected: Bool

    /// Whether the content detection resulted in a content filtering action.
    public let filtered: Bool

}

/// Generated model for AzureContentFilterForResponsesAPI
public struct GeneratedContentFilterForResponsesAPI: Codable, Equatable {
    /// Indicate if the response is blocked.
    public let blocked: Bool

    public let contentFilterOffsets: GeneratedContentFilterResultOffsets

    /// A content filter result for a single response item produced by a generative AI system.
    public let contentFilterResults: String

    /// The name of the source type of the message.
    public let sourceType: String

    private enum CodingKeys: String, CodingKey {
        case blocked
        case contentFilterOffsets = "content_filter_offsets"
        case contentFilterResults = "content_filter_results"
        case sourceType = "source_type"
    }

}

/// Generated model for AzureContentFilterPersonallyIdentifiableInformationResult
public struct GeneratedContentFilterPersonallyIdentifiableInformationResult: Codable, Equatable {
    /// The redacted text with PII information removed or masked.
    public let redactedText: String?

    /// Detailed results for individual PIIHarmSubCategory(s).
    public let subCategories: [GeneratedPiiSubCategoryResult]?

    private enum CodingKeys: String, CodingKey {
        case redactedText = "redacted_text"
        case subCategories = "sub_categories"
    }

}

/// Generated model for AzureContentFilterResultOffsets
public struct GeneratedContentFilterResultOffsets: Codable, Equatable {
    public let checkOffset: Int

    public let endOffset: Int

    public let startOffset: Int

    private enum CodingKeys: String, CodingKey {
        case checkOffset = "check_offset"
        case endOffset = "end_offset"
        case startOffset = "start_offset"
    }

}

/// Generated model for AzureContentFilterResultsForResponsesAPI
public struct GeneratedContentFilterResultsForResponsesAPI: Codable, Equatable {
    /// A collection of binary filtering outcomes for configured custom blocklists.
    public let customBlocklists: String?

    /// A collection of binary filtering outcomes for configured custom topics.
    public let customTopics: String?

    /// If present, details about an error that prevented content filtering from completing its evaluation.
    public let error: SAOAIJSONValue?

    /// A content filter category that can refer to any content that attacks or uses pejorative or discriminatory language with reference to a person or identity group based on certain differentiating attr...
    public let hate: String?

    /// A detection result that describes attacks on systems powered by Generative AI models that can happen every time an application processes information that wasnâ€™t directly authored by either the deve...
    public let indirectAttack: String?

    /// A detection result that describes user prompt injection attacks, where malicious users deliberately exploit system vulnerabilities to elicit unauthorized behavior from the LLM. This could lead to i...
    public let jailbreak: String

    /// A detection result that describes matches against Personal Identifiable Information with configurable subcategories.
    public let personallyIdentifiableInformation: String?

    /// A detection result that identifies whether crude, vulgar, or otherwise objection language is present in the content.
    public let profanity: String?

    /// A detection result that describes a match against licensed code or other protected source material.
    public let protectedMaterialCode: SAOAIJSONValue?

    /// A detection result that describes a match against text protected under copyright or other status.
    public let protectedMaterialText: String?

    /// A content filter category that describes language related to physical actions intended to purposely hurt, injure, damage one's body or kill oneself.
    public let selfHarm: String?

    /// A content filter category for language related to anatomical organs and genitals, romantic relationships, acts portrayed in erotic or affectionate terms, pregnancy, physical sexual acts, including ...
    public let sexual: String?

    /// A detection result that indicates if the execution flow still sticks the plan.
    public let taskAdherence: String

    public let ungroundedMaterial: GeneratedContentFilterCompletionTextSpanDetectionResult?

    /// A content filter category for language related to physical actions intended to hurt, injure, damage, or kill someone or something; describes weapons, guns and related entities, such as manufactures...
    public let violence: String?

    private enum CodingKeys: String, CodingKey {
        case customBlocklists = "custom_blocklists"
        case customTopics = "custom_topics"
        case error
        case hate
        case indirectAttack = "indirect_attack"
        case jailbreak
        case personallyIdentifiableInformation = "personally_identifiable_information"
        case profanity
        case protectedMaterialCode = "protected_material_code"
        case protectedMaterialText = "protected_material_text"
        case selfHarm = "self_harm"
        case sexual
        case taskAdherence = "task_adherence"
        case ungroundedMaterial = "ungrounded_material"
        case violence
    }

}

/// Generated model for AzureContentFilterSeverityResult
public struct GeneratedContentFilterSeverityResult: Codable, Equatable {
    /// Whether the content severity resulted in a content filtering action.
    public let filtered: Bool

    /// The labeled severity of the content.
    public let severity: String

}

/// Generated model for AzurePiiSubCategoryResult
public struct GeneratedPiiSubCategoryResult: Codable, Equatable {
    /// Whether the labeled content subcategory was detected in the content.
    public let detected: Bool

    /// Whether the content detection resulted in a content filtering action for this subcategory.
    public let filtered: Bool

    /// Whether the content was redacted for this subcategory.
    public let redacted: Bool

    /// The PIIHarmSubCategory that was evaluated.
    public let subCategory: String

    private enum CodingKeys: String, CodingKey {
        case detected
        case filtered
        case redacted
        case subCategory = "sub_category"
    }

}

/// Generated model for OpenAI.Annotation
public struct GeneratedAnnotation: Codable, Equatable {
    public let type: String

}

/// Generated model for OpenAI.ConversationParam-2
public struct GeneratedConversationParam-2: Codable, Equatable {
    /// The unique ID of the conversation.
    public let id: String

}

/// Generated model for OpenAI.ConversationReference
public struct GeneratedConversationReference: Codable, Equatable {
    /// The unique ID of the conversation that this response was associated with.
    public let id: String

}

/// Generated model for OpenAI.CreateEmbeddingRequest
public struct GeneratedEmbeddingRequest: Codable, Equatable {
    /// The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
    public let dimensions: Int?

    /// The format to return the embeddings in. Can be either `float` or `base64`.
    public let encodingFormat: String?

    /// Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input...
    public let input: String

    /// ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.
    public let model: String

    /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.
    public let user: String?

    private enum CodingKeys: String, CodingKey {
        case dimensions
        case encodingFormat = "encoding_format"
        case input
        case model
        case user
    }

}

/// Generated model for OpenAI.CreateEmbeddingResponse
public struct GeneratedEmbeddingResponse: Codable, Equatable {
    /// The list of embeddings generated by the model.
    public let data: [GeneratedEmbedding]

    /// The name of the model used to generate the embedding.
    public let model: String

    /// The object type, which is always "list".
    public let object: String

    /// The usage information for the request.
    public let usage: String

}

/// Generated model for OpenAI.CreateEmbeddingResponseUsage
public struct GeneratedEmbeddingResponseUsage: Codable, Equatable {
    public let promptTokens: Int

    public let totalTokens: Int

    private enum CodingKeys: String, CodingKey {
        case promptTokens = "prompt_tokens"
        case totalTokens = "total_tokens"
    }

}

/// Generated model for OpenAI.CreateFileRequest
public struct GeneratedFileRequest: Codable, Equatable {
    public let expiresAfter: SAOAIJSONValue

    /// The File object (not file name) to be uploaded.
    public let file: String

    /// The intended purpose of the uploaded file. One of: - `assistants`: Used in the Assistants API - `batch`: Used in the Batch API - `fine-tune`: Used for fine-tuning - `evals`: Used for eval data sets
    public let purpose: String

    private enum CodingKeys: String, CodingKey {
        case expiresAfter = "expires_after"
        case file
        case purpose
    }

}

/// Generated model for OpenAI.CreateResponse
public struct GeneratedResponseRequest: Codable, Equatable {
    public let background: String?

    public let conversation: String?

    public let include: String?

    public let input: String?

    public let instructions: String?

    public let maxOutputTokens: String?

    public let maxToolCalls: String?

    public let metadata: String?

    /// Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model gu...
    public let model: String?

    public let parallelToolCalls: String?

    public let previousResponseId: String?

    public let prompt: GeneratedPrompt?

    /// Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. Learn more.
    public let promptCacheKey: String?

    public let promptCacheRetention: String?

    public let reasoning: String?

    /// A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user. We recommend hashing ...
    public let safetyIdentifier: String?

    public let store: String?

    public let stream: String?

    public let streamOptions: String?

    public let temperature: String?

    public let text: GeneratedResponseTextParam?

    public let toolChoice: GeneratedToolChoiceParam?

    /// An array of tools the model may call while generating a response. You can specify which tool to use by setting the `tool_choice` parameter. The two categories of tools you can provide the model are...
    public let tools: GeneratedToolsArray?

    public let topLogprobs: String?

    public let topP: String?

    public let truncation: String?

    /// This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations. A stable identifier for your end-users. Used to boost c...
    public let user: String?

    private enum CodingKeys: String, CodingKey {
        case background
        case conversation
        case include
        case input
        case instructions
        case maxOutputTokens = "max_output_tokens"
        case maxToolCalls = "max_tool_calls"
        case metadata
        case model
        case parallelToolCalls = "parallel_tool_calls"
        case previousResponseId = "previous_response_id"
        case prompt
        case promptCacheKey = "prompt_cache_key"
        case promptCacheRetention = "prompt_cache_retention"
        case reasoning
        case safetyIdentifier = "safety_identifier"
        case store
        case stream
        case streamOptions = "stream_options"
        case temperature
        case text
        case toolChoice = "tool_choice"
        case tools
        case topLogprobs = "top_logprobs"
        case topP = "top_p"
        case truncation
        case user
    }

}

/// Generated model for OpenAI.DeleteFileResponse
public struct GeneratedDeleteFileResponse: Codable, Equatable {
    public let deleted: Bool

    public let id: String

    public let object: String

}

/// Generated model for OpenAI.Embedding
public struct GeneratedEmbedding: Codable, Equatable {
    /// The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the embedding guide.
    public let embedding: [Float]

    /// The index of the embedding in the list of embeddings.
    public let index: Int

    /// The object type, which is always "embedding".
    public let object: String

}

/// Generated model for OpenAI.InputFileContent
public struct GeneratedInputFileContent: Codable, Equatable {
    /// The content of the file to be sent to the model.
    public let fileData: String?

    public let fileId: String?

    /// The URL of the file to be sent to the model.
    public let fileUrl: URL?

    /// The name of the file to be sent to the model.
    public let filename: String?

    /// The type of the input item. Always `input_file`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case fileData = "file_data"
        case fileId = "file_id"
        case fileUrl = "file_url"
        case filename
        case type
    }

}

/// Generated model for OpenAI.InputImageContent
public struct GeneratedInputImageContent: Codable, Equatable {
    /// The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.
    public let detail: String

    public let fileId: String?

    public let imageUrl: String?

    /// The type of the input item. Always `input_image`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case detail
        case fileId = "file_id"
        case imageUrl = "image_url"
        case type
    }

}

/// Generated model for OpenAI.InputItem
public struct GeneratedInputItem: Codable, Equatable {
    public let type: String

}

/// Generated model for OpenAI.InputTextContent
public struct GeneratedInputTextContent: Codable, Equatable {
    /// The text input to the model.
    public let text: String

    /// The type of the input item. Always `input_text`.
    public let type: String

}

/// Generated model for OpenAI.ItemResource
public struct GeneratedItemResource: Codable, Equatable {
    public let type: String

}

/// Generated model for OpenAI.ListFilesResponse
public struct GeneratedListFilesResponse: Codable, Equatable {
    public let data: [GeneratedOpenAIFile]

    public let firstId: String

    public let hasMore: Bool

    public let lastId: String

    public let object: String

    private enum CodingKeys: String, CodingKey {
        case data
        case firstId = "first_id"
        case hasMore = "has_more"
        case lastId = "last_id"
        case object
    }

}

/// Generated model for OpenAI.Metadata
public struct GeneratedMetadata: Codable, Equatable {
}

/// Generated model for OpenAI.OpenAIFile
public struct GeneratedOpenAIFile: Codable, Equatable {
    /// The size of the file, in bytes.
    public let bytes: Int

    /// The Unix timestamp (in seconds) for when the file was created.
    public let createdAt: Int

    /// The Unix timestamp (in seconds) for when the file will expire.
    public let expiresAt: Int?

    /// The name of the file.
    public let filename: String

    /// The file identifier, which can be referenced in the API endpoints.
    public let id: String

    /// The object type, which is always `file`.
    public let object: String

    /// The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune` and `fine-tune-results`.
    public let purpose: String

    public let status: String

    /// Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.
    public let statusDetails: String?

    private enum CodingKeys: String, CodingKey {
        case bytes
        case createdAt = "created_at"
        case expiresAt = "expires_at"
        case filename
        case id
        case object
        case purpose
        case status
        case statusDetails = "status_details"
    }

}

/// Generated model for OpenAI.OutputContent
public struct GeneratedOutputContent: Codable, Equatable {
    public let type: String

}

/// Generated model for OpenAI.OutputItem
public struct GeneratedOutputItem: Codable, Equatable {
    public let type: String

}

/// Generated model for OpenAI.Prompt
public struct GeneratedPrompt: Codable, Equatable {
    /// The unique identifier of the prompt template to use.
    public let id: String

    public let variables: String?

    public let version: String?

}

/// Generated model for OpenAI.Reasoning
public struct GeneratedReasoning: Codable, Equatable {
    public let effort: String?

    public let generateSummary: String?

    public let summary: String?

    private enum CodingKeys: String, CodingKey {
        case effort
        case generateSummary = "generate_summary"
        case summary
    }

}

/// Generated model for OpenAI.Response
public struct GeneratedResponse: Codable, Equatable {
    public let background: String?

    public let completedAt: String?

    /// The content filter results from RAI.
    public let contentFilters: [GeneratedContentFilterForResponsesAPI]

    public let conversation: String?

    /// Unix timestamp (in seconds) of when this Response was created.
    public let createdAt: Int

    public let error: String

    /// Unique identifier for this Response.
    public let id: String

    public let incompleteDetails: String

    public let instructions: String

    public let maxOutputTokens: String?

    public let maxToolCalls: String?

    public let metadata: String?

    /// Model ID used to generate the response, like `gpt-4o` or `o3`. OpenAI offers a wide range of models with different capabilities, performance characteristics, and price points. Refer to the model gu...
    public let model: String?

    /// The object type of this resource - always set to `response`.
    public let object: String

    /// An array of content items generated by the model. - The length and order of items in the `output` array is dependent on the model's response. - Rather than accessing the first item in the `output` ...
    public let output: [GeneratedOutputItem]

    public let outputText: String?

    /// Whether to allow the model to run tool calls in parallel.
    public let parallelToolCalls: Bool

    public let previousResponseId: String?

    public let prompt: GeneratedPrompt?

    /// Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. Learn more.
    public let promptCacheKey: String?

    public let promptCacheRetention: String?

    public let reasoning: String?

    /// A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user. We recommend hashing ...
    public let safetyIdentifier: String?

    /// The status of the response generation. One of `completed`, `failed`, `in_progress`, `cancelled`, `queued`, or `incomplete`.
    public let status: String?

    public let temperature: String?

    public let text: GeneratedResponseTextParam?

    public let toolChoice: GeneratedToolChoiceParam?

    public let tools: GeneratedToolsArray?

    public let topLogprobs: String?

    public let topP: String?

    public let truncation: String?

    public let usage: GeneratedResponseUsage?

    /// This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations. A stable identifier for your end-users. Used to boost c...
    public let user: String?

    private enum CodingKeys: String, CodingKey {
        case background
        case completedAt = "completed_at"
        case contentFilters = "content_filters"
        case conversation
        case createdAt = "created_at"
        case error
        case id
        case incompleteDetails = "incomplete_details"
        case instructions
        case maxOutputTokens = "max_output_tokens"
        case maxToolCalls = "max_tool_calls"
        case metadata
        case model
        case object
        case output
        case outputText = "output_text"
        case parallelToolCalls = "parallel_tool_calls"
        case previousResponseId = "previous_response_id"
        case prompt
        case promptCacheKey = "prompt_cache_key"
        case promptCacheRetention = "prompt_cache_retention"
        case reasoning
        case safetyIdentifier = "safety_identifier"
        case status
        case temperature
        case text
        case toolChoice = "tool_choice"
        case tools
        case topLogprobs = "top_logprobs"
        case topP = "top_p"
        case truncation
        case usage
        case user
    }

}

/// Generated model for OpenAI.ResponseAudioDeltaEvent
public struct GeneratedResponseAudioDeltaEvent: Codable, Equatable {
    /// A chunk of Base64 encoded response audio bytes.
    public let delta: String

    /// A sequence number for this chunk of the stream response.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.audio.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case delta
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseAudioTranscriptDeltaEvent
public struct GeneratedResponseAudioTranscriptDeltaEvent: Codable, Equatable {
    /// The partial transcript of the audio response.
    public let delta: String

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.audio.transcript.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case delta
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseCodeInterpreterCallCodeDeltaEvent
public struct GeneratedResponseCodeInterpreterCallCodeDeltaEvent: Codable, Equatable {
    /// The partial code snippet being streamed by the code interpreter.
    public let delta: String

    /// The unique identifier of the code interpreter tool call item.
    public let itemId: String

    /// The index of the output item in the response for which the code is being streamed.
    public let outputIndex: Int

    /// The sequence number of this event, used to order streaming events.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.code_interpreter_call_code.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case delta
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseCodeInterpreterCallInProgressEvent
public struct GeneratedResponseCodeInterpreterCallInProgressEvent: Codable, Equatable {
    /// The unique identifier of the code interpreter tool call item.
    public let itemId: String

    /// The index of the output item in the response for which the code interpreter call is in progress.
    public let outputIndex: Int

    /// The sequence number of this event, used to order streaming events.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.code_interpreter_call.in_progress`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseCodeInterpreterCallInterpretingEvent
public struct GeneratedResponseCodeInterpreterCallInterpretingEvent: Codable, Equatable {
    /// The unique identifier of the code interpreter tool call item.
    public let itemId: String

    /// The index of the output item in the response for which the code interpreter is interpreting code.
    public let outputIndex: Int

    /// The sequence number of this event, used to order streaming events.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.code_interpreter_call.interpreting`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseContentPartAddedEvent
public struct GeneratedResponseContentPartAddedEvent: Codable, Equatable {
    /// The index of the content part that was added.
    public let contentIndex: Int

    /// The ID of the output item that the content part was added to.
    public let itemId: String

    /// The index of the output item that the content part was added to.
    public let outputIndex: Int

    /// The content part that was added.
    public let part: String

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.content_part.added`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case contentIndex = "content_index"
        case itemId = "item_id"
        case outputIndex = "output_index"
        case part
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseCreatedEvent
public struct GeneratedResponseCreatedEvent: Codable, Equatable {
    /// The response that was created.
    public let response: String

    /// The sequence number for this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.created`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case response
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseCustomToolCallInputDeltaEvent
public struct GeneratedResponseCustomToolCallInputDeltaEvent: Codable, Equatable {
    /// The incremental input data (delta) for the custom tool call.
    public let delta: String

    /// Unique identifier for the API item associated with this event.
    public let itemId: String

    /// The index of the output this delta applies to.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The event type identifier.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case delta
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseError
public struct GeneratedResponseError: Codable, Equatable {
    public let code: GeneratedResponseErrorCode

    /// A human-readable description of the error.
    public let message: String

}

/// Generated model for OpenAI.ResponseErrorEvent
public struct GeneratedResponseErrorEvent: Codable, Equatable {
    public let code: String

    /// The error message.
    public let message: String

    public let param: String

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `error`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case code
        case message
        case param
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseFailedEvent
public struct GeneratedResponseFailedEvent: Codable, Equatable {
    /// The response that failed.
    public let response: String

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.failed`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case response
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseFileSearchCallInProgressEvent
public struct GeneratedResponseFileSearchCallInProgressEvent: Codable, Equatable {
    /// The ID of the output item that the file search call is initiated.
    public let itemId: String

    /// The index of the output item that the file search call is initiated.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.file_search_call.in_progress`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseFileSearchCallSearchingEvent
public struct GeneratedResponseFileSearchCallSearchingEvent: Codable, Equatable {
    /// The ID of the output item that the file search call is initiated.
    public let itemId: String

    /// The index of the output item that the file search call is searching.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.file_search_call.searching`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseFunctionCallArgumentsDeltaEvent
public struct GeneratedResponseFunctionCallArgumentsDeltaEvent: Codable, Equatable {
    /// The function-call arguments delta that is added.
    public let delta: String

    /// The ID of the output item that the function-call arguments delta is added to.
    public let itemId: String

    /// The index of the output item that the function-call arguments delta is added to.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.function_call_arguments.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case delta
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseImageGenCallGeneratingEvent
public struct GeneratedResponseImageGenCallGeneratingEvent: Codable, Equatable {
    /// The unique identifier of the image generation item being processed.
    public let itemId: String

    /// The index of the output item in the response's output array.
    public let outputIndex: Int

    /// The sequence number of the image generation item being processed.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.image_generation_call.generating'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseImageGenCallInProgressEvent
public struct GeneratedResponseImageGenCallInProgressEvent: Codable, Equatable {
    /// The unique identifier of the image generation item being processed.
    public let itemId: String

    /// The index of the output item in the response's output array.
    public let outputIndex: Int

    /// The sequence number of the image generation item being processed.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.image_generation_call.in_progress'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseImageGenCallPartialImageEvent
public struct GeneratedResponseImageGenCallPartialImageEvent: Codable, Equatable {
    /// The unique identifier of the image generation item being processed.
    public let itemId: String

    /// The index of the output item in the response's output array.
    public let outputIndex: Int

    /// Base64-encoded partial image data, suitable for rendering as an image.
    public let partialImageB64: String

    /// 0-based index for the partial image (backend is 1-based, but this is 0-based for the user).
    public let partialImageIndex: Int

    /// The sequence number of the image generation item being processed.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.image_generation_call.partial_image'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case partialImageB64 = "partial_image_b64"
        case partialImageIndex = "partial_image_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseInProgressEvent
public struct GeneratedResponseInProgressEvent: Codable, Equatable {
    /// The response that is in progress.
    public let response: String

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.in_progress`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case response
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseIncompleteDetails
public struct GeneratedResponseIncompleteDetails: Codable, Equatable {
    public let reason: String?

}

/// Generated model for OpenAI.ResponseIncompleteEvent
public struct GeneratedResponseIncompleteEvent: Codable, Equatable {
    /// The response that was incomplete.
    public let response: String

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.incomplete`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case response
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseItemList
public struct GeneratedResponseItemList: Codable, Equatable {
    /// A list of items used to generate this response.
    public let data: [GeneratedItemResource]

    /// The ID of the first item in the list.
    public let firstId: String

    /// Whether there are more items available.
    public let hasMore: Bool

    /// The ID of the last item in the list.
    public let lastId: String

    /// The type of object returned, must be `list`.
    public let object: String

    private enum CodingKeys: String, CodingKey {
        case data
        case firstId = "first_id"
        case hasMore = "has_more"
        case lastId = "last_id"
        case object
    }

}

/// Generated model for OpenAI.ResponseLogProb
public struct GeneratedResponseLogProb: Codable, Equatable {
    /// The log probability of this token.
    public let logprob: Double

    /// A possible text token.
    public let token: String

    /// The log probability of the top 20 most likely tokens.
    public let topLogprobs: [GeneratedResponseLogProbTopLogprobs]?

    private enum CodingKeys: String, CodingKey {
        case logprob
        case token
        case topLogprobs = "top_logprobs"
    }

}

/// Generated model for OpenAI.ResponseLogProbTopLogprobs
public struct GeneratedResponseLogProbTopLogprobs: Codable, Equatable {
    public let logprob: Double?

    public let token: String?

}

/// Generated model for OpenAI.ResponseMCPCallArgumentsDeltaEvent
public struct GeneratedResponseMCPCallArgumentsDeltaEvent: Codable, Equatable {
    /// A JSON string containing the partial update to the arguments for the MCP tool call.
    public let delta: String

    /// The unique identifier of the MCP tool call item being processed.
    public let itemId: String

    /// The index of the output item in the response's output array.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.mcp_call_arguments.delta'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case delta
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseMCPCallFailedEvent
public struct GeneratedResponseMCPCallFailedEvent: Codable, Equatable {
    /// The ID of the MCP tool call item that failed.
    public let itemId: String

    /// The index of the output item that failed.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.mcp_call.failed'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseMCPCallInProgressEvent
public struct GeneratedResponseMCPCallInProgressEvent: Codable, Equatable {
    /// The unique identifier of the MCP tool call item being processed.
    public let itemId: String

    /// The index of the output item in the response's output array.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.mcp_call.in_progress'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseMCPListToolsFailedEvent
public struct GeneratedResponseMCPListToolsFailedEvent: Codable, Equatable {
    /// The ID of the MCP tool call item that failed.
    public let itemId: String

    /// The index of the output item that failed.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.mcp_list_tools.failed'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseMCPListToolsInProgressEvent
public struct GeneratedResponseMCPListToolsInProgressEvent: Codable, Equatable {
    /// The ID of the MCP tool call item that is being processed.
    public let itemId: String

    /// The index of the output item that is being processed.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.mcp_list_tools.in_progress'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseOutputItemAddedEvent
public struct GeneratedResponseOutputItemAddedEvent: Codable, Equatable {
    /// The output item that was added.
    public let item: String

    /// The index of the output item that was added.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.output_item.added`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case item
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseOutputTextAnnotationAddedEvent
public struct GeneratedResponseOutputTextAnnotationAddedEvent: Codable, Equatable {
    /// The annotation object being added. (See annotation schema for details.)
    public let annotation: String

    /// The index of the annotation within the content part.
    public let annotationIndex: Int

    /// The index of the content part within the output item.
    public let contentIndex: Int

    /// The unique identifier of the item to which the annotation is being added.
    public let itemId: String

    /// The index of the output item in the response's output array.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.output_text.annotation.added'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case annotation
        case annotationIndex = "annotation_index"
        case contentIndex = "content_index"
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponsePromptVariables
public struct GeneratedResponsePromptVariables: Codable, Equatable {
}

/// Generated model for OpenAI.ResponseQueuedEvent
public struct GeneratedResponseQueuedEvent: Codable, Equatable {
    /// The full response object that is queued.
    public let response: String

    /// The sequence number for this event.
    public let sequenceNumber: Int

    /// The type of the event. Always 'response.queued'.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case response
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseReasoningSummaryPartAddedEvent
public struct GeneratedResponseReasoningSummaryPartAddedEvent: Codable, Equatable {
    /// The ID of the item this summary part is associated with.
    public let itemId: String

    /// The index of the output item this summary part is associated with.
    public let outputIndex: Int

    /// The summary part that was added.
    public let part: String

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The index of the summary part within the reasoning summary.
    public let summaryIndex: Int

    /// The type of the event. Always `response.reasoning_summary_part.added`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case part
        case sequenceNumber = "sequence_number"
        case summaryIndex = "summary_index"
        case type
    }

}

/// Generated model for OpenAI.ResponseReasoningSummaryPartAddedEventPart
public struct GeneratedResponseReasoningSummaryPartAddedEventPart: Codable, Equatable {
    public let text: String

    public let type: String

}

/// Generated model for OpenAI.ResponseReasoningSummaryTextDeltaEvent
public struct GeneratedResponseReasoningSummaryTextDeltaEvent: Codable, Equatable {
    /// The text delta that was added to the summary.
    public let delta: String

    /// The ID of the item this summary text delta is associated with.
    public let itemId: String

    /// The index of the output item this summary text delta is associated with.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The index of the summary part within the reasoning summary.
    public let summaryIndex: Int

    /// The type of the event. Always `response.reasoning_summary_text.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case delta
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case summaryIndex = "summary_index"
        case type
    }

}

/// Generated model for OpenAI.ResponseReasoningTextDeltaEvent
public struct GeneratedResponseReasoningTextDeltaEvent: Codable, Equatable {
    /// The index of the reasoning content part this delta is associated with.
    public let contentIndex: Int

    /// The text delta that was added to the reasoning content.
    public let delta: String

    /// The ID of the item this reasoning text delta is associated with.
    public let itemId: String

    /// The index of the output item this reasoning text delta is associated with.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.reasoning_text.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case contentIndex = "content_index"
        case delta
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseRefusalDeltaEvent
public struct GeneratedResponseRefusalDeltaEvent: Codable, Equatable {
    /// The index of the content part that the refusal text is added to.
    public let contentIndex: Int

    /// The refusal text that is added.
    public let delta: String

    /// The ID of the output item that the refusal text is added to.
    public let itemId: String

    /// The index of the output item that the refusal text is added to.
    public let outputIndex: Int

    /// The sequence number of this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.refusal.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case contentIndex = "content_index"
        case delta
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseStreamOptions
public struct GeneratedResponseStreamOptions: Codable, Equatable {
    /// When true, stream obfuscation will be enabled. Stream obfuscation adds random characters to an `obfuscation` field on streaming delta events to normalize payload sizes as a mitigation to certain si...
    public let includeObfuscation: Bool?

    private enum CodingKeys: String, CodingKey {
        case includeObfuscation = "include_obfuscation"
    }

}

/// Generated model for OpenAI.ResponseTextDeltaEvent
public struct GeneratedResponseTextDeltaEvent: Codable, Equatable {
    /// The index of the content part that the text delta was added to.
    public let contentIndex: Int

    /// The text delta that was added.
    public let delta: String

    /// The ID of the output item that the text delta was added to.
    public let itemId: String

    /// The log probabilities of the tokens in the delta.
    public let logprobs: [GeneratedResponseLogProb]

    /// The index of the output item that the text delta was added to.
    public let outputIndex: Int

    /// The sequence number for this event.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.output_text.delta`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case contentIndex = "content_index"
        case delta
        case itemId = "item_id"
        case logprobs
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseTextParam
public struct GeneratedResponseTextParam: Codable, Equatable {
    public let format: GeneratedTextResponseFormatConfiguration?

    public let verbosity: String?

}

/// Generated model for OpenAI.ResponseUsage
public struct GeneratedResponseUsage: Codable, Equatable {
    /// The number of input tokens.
    public let inputTokens: Int

    /// A detailed breakdown of the input tokens.
    public let inputTokensDetails: String

    /// The number of output tokens.
    public let outputTokens: Int

    /// A detailed breakdown of the output tokens.
    public let outputTokensDetails: String

    /// The total number of tokens used.
    public let totalTokens: Int

    private enum CodingKeys: String, CodingKey {
        case inputTokens = "input_tokens"
        case inputTokensDetails = "input_tokens_details"
        case outputTokens = "output_tokens"
        case outputTokensDetails = "output_tokens_details"
        case totalTokens = "total_tokens"
    }

}

/// Generated model for OpenAI.ResponseUsageInputTokensDetails
public struct GeneratedResponseUsageInputTokensDetails: Codable, Equatable {
    public let cachedTokens: Int

    private enum CodingKeys: String, CodingKey {
        case cachedTokens = "cached_tokens"
    }

}

/// Generated model for OpenAI.ResponseUsageOutputTokensDetails
public struct GeneratedResponseUsageOutputTokensDetails: Codable, Equatable {
    public let reasoningTokens: Int

    private enum CodingKeys: String, CodingKey {
        case reasoningTokens = "reasoning_tokens"
    }

}

/// Generated model for OpenAI.ResponseWebSearchCallInProgressEvent
public struct GeneratedResponseWebSearchCallInProgressEvent: Codable, Equatable {
    /// Unique ID for the output item associated with the web search call.
    public let itemId: String

    /// The index of the output item that the web search call is associated with.
    public let outputIndex: Int

    /// The sequence number of the web search call being processed.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.web_search_call.in_progress`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.ResponseWebSearchCallSearchingEvent
public struct GeneratedResponseWebSearchCallSearchingEvent: Codable, Equatable {
    /// Unique ID for the output item associated with the web search call.
    public let itemId: String

    /// The index of the output item that the web search call is associated with.
    public let outputIndex: Int

    /// The sequence number of the web search call being processed.
    public let sequenceNumber: Int

    /// The type of the event. Always `response.web_search_call.searching`.
    public let type: String

    private enum CodingKeys: String, CodingKey {
        case itemId = "item_id"
        case outputIndex = "output_index"
        case sequenceNumber = "sequence_number"
        case type
    }

}

/// Generated model for OpenAI.TextResponseFormatConfiguration
public struct GeneratedTextResponseFormatConfiguration: Codable, Equatable {
    public let type: String

}

/// Generated model for OpenAI.Tool
public struct GeneratedTool: Codable, Equatable {
    public let type: String

}

/// Generated model for OpenAI.ToolChoiceParam
public struct GeneratedToolChoiceParam: Codable, Equatable {
    public let type: String

}
